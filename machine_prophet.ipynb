{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import os\n",
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta, datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlesize=14, titlepad=10)\n",
    "%matplotlib inline\n",
    "\n",
    "# EDA\n",
    "import klib\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from bayes_opt import BayesianOptimization\n",
    "# Modeling\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from catboost import Pool\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import ensemble, metrics\n",
    "from sklearn.linear_model import ARDRegression, BayesianRidge\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "from scipy.stats.mstats import gmean\n",
    "from vecstack import stacking\n",
    "set_log_level(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f65af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bcf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportrmsedata=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadaee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ci(y, z=1.96):\n",
    "    n = int(y.shape[-1])\n",
    "    n_sqrt, mean, std = np.sqrt(n), np.mean(y), np.std(y, axis=0)\n",
    "\n",
    "    upper_ci = y + z * std / n_sqrt\n",
    "    lower_ci = y - z * std / n_sqrt\n",
    "    return upper_ci, lower_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수 선언부-수정 필요\n",
    "def plot_predictions60(name_, actual, pred):\n",
    "    \n",
    "    upper_ci, lower_ci = calculate_ci(forecast['yhat_avg'])\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    plt.plot(fore['ds'][-60:], fore['yhat_avg'][-60:], color='k', label='y_fit')\n",
    "    plt.plot(fore['ds'][-60:], fore['y'][-60:], label='y_true')\n",
    "    plt.plot(fore['ds'][-7:], fore['yhat_avg'][-7:], color='g', label='y_trends')\n",
    "\n",
    "    plt.fill_between(fore['ds'][-7:], upper_ci[-7:], lower_ci[-7:], alpha=0.3)\n",
    "\n",
    "    plt.title('Forcasting stock price')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('price')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    #종료 후 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2978b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수 선언부-수정 필요\n",
    "def plot_predictions(name_, actual, pred):\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    m.plot(forecast, xlabel=\"Date\", ylabel=\"Close\", ax=ax)\n",
    "\n",
    "    ax.xaxis.label.set_size(28)\n",
    "    ax.yaxis.label.set_size(28)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    ax.set_title(\"prediction Stocks\", fontsize=28, fontweight=\"bold\")\n",
    "    \n",
    "    #종료 후 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_eval(name_, actual, pred):\n",
    "    global predictions\n",
    "    global colors\n",
    "    global exportrmsedata\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    ax.plot(metrics[\"RMSE\"], '-b', linewidth=6, label=\"Training Loss\")  \n",
    "    ax.plot(metrics[\"RMSE_val\"], '-r', linewidth=2, label=\"Validation Loss\")\n",
    "\n",
    "    # You can use metrics[\"SmoothL1Loss\"] and metrics[\"SmoothL1Loss_val\"] too.\n",
    "\n",
    "    ax.legend(loc='center right', fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=28, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Loss\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "    ax.set_title(\"Model Loss (RMSE)\", fontsize=28, fontweight=\"bold\")    \n",
    "\n",
    "    if exportrmsedata==True:\n",
    "        plt.gcf().subplots_adjust(left=0.20)\n",
    "        plt.savefig(f'C:\\\\dohwi\\\\project\\\\rmsedatas\\\\{indexnum}_Rmse.png')\n",
    "        exportrmsedata=False\n",
    "        #종료 후 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b122e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcompanylist(address):\n",
    "    company_df=pd.read_csv(address)\n",
    "    #여기 절대 경로를 사용자에 맞추어 바꾸어 주세요.\n",
    "    companylist=company_df[\"종목코드\"].to_list()\n",
    "    for i in range(len(companylist)):\n",
    "        companylist[i]=str(companylist[i]).rjust(6,\"0\")#padding 함수 사용\n",
    "    return companylist\n",
    "\n",
    "companyaddress=\"C:\\dohwi\\project\\listed_companies.csv\"\n",
    "indexnumlist=getcompanylist(companyaddress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7214777",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexnum in indexnumlist:\n",
    "    try:\n",
    "        #여기 부터는 여러 번 실행하며 데이터를 얻어야 함.\n",
    "        #데이터 가져오기\n",
    "        main_df=pd.read_csv(f'C:\\dohwi\\project\\dataset\\companydatas\\Totaldata_{indexnum}_ref_IXIC.csv',index_col=\"Date\")\n",
    "        sup_df=pd.read_csv(f'C:\\dohwi\\project\\dataset\\companydatas\\supportindexscaled_{indexnum}_ref_IXIC.csv',index_col=\"Date\")\n",
    "        df=pd.merge(main_df,sup_df,on=\"Date\")\n",
    "        df=df.drop([df.columns[0],\"ma_5\",\"ma_20\",\"ma_60\",\"ma_120\"],axis=1)\n",
    "        X = df.copy()\n",
    "        X = X.drop('Close',axis = 'columns')\n",
    "        y = df['Close']\n",
    "        y = pd.DataFrame(y)\n",
    "        X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.3, shuffle =False, random_state=0)\n",
    "        lr = LinearRegression(n_jobs=4)\n",
    "        ridge = Ridge(alpha=1)\n",
    "        lasso = Lasso()\n",
    "        ard = ARDRegression()\n",
    "        bayesian = BayesianRidge()\n",
    "        models = [lr , ridge,lasso,ard, bayesian]\n",
    "        X_train= X_train.reset_index(drop=True)\n",
    "        X_dev= X_dev.reset_index(drop=True)\n",
    "        y_dev = y_dev.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_dev = y_dev.values\n",
    "        y_train = y_train.values\n",
    "        y_dev = np.array(y_dev).flatten().tolist()\n",
    "        y_train = np.array(y_train).flatten().tolist()\n",
    "        ts = time.time()\n",
    "\n",
    "\n",
    "        #최종 주가 예측-(베이지안,ridge,ard 모델 3개의 voting ensemble 형태로 수행)\n",
    "        single_models = [\n",
    "            ('bayesian ', bayesian),\n",
    "            ('ridge', ridge),\n",
    "            #('rfr', rfr),\n",
    "            ('ard',ard)\n",
    "            \n",
    "        ]\n",
    "        model = VotingRegressor(single_models, n_jobs=6)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        VotingRegressor(estimators=[('linear_reg',\n",
    "                                    LinearRegression(copy_X=True, fit_intercept=True,\n",
    "                                                    n_jobs=6, normalize=False)),\n",
    "                                    ('ridge',\n",
    "                                    Ridge(alpha=1, copy_X=True, fit_intercept=True,\n",
    "                                        max_iter=None, normalize=False,\n",
    "                                        random_state=None, solver='auto',\n",
    "                                        tol=0.001)),\n",
    "                                    ('ard',\n",
    "                                    ARDRegression())],\n",
    "                                                                \n",
    "                                    \n",
    "                        n_jobs=6, weights=None)\n",
    "\n",
    "        y_pred = model.predict(X_dev)\n",
    "        \n",
    "        f_df=df[int(len(df)*0.7):]\n",
    "        \n",
    "        prcp_data = pd.DataFrame({'ds':f_df.index, 'y':y_pred})\n",
    "        prcp_data['ds']=pd.to_datetime(prcp_data['ds'], format='%Y-%m-%d')\n",
    "        \n",
    "        m = NeuralProphet(\n",
    "        growth=\"linear\",\n",
    "        n_forecasts=7, #7일 예측\n",
    "        n_lags = 7,\n",
    "        num_hidden_layers=4,\n",
    "        d_hidden=16,\n",
    "        yearly_seasonality=True,\n",
    "        learning_rate=0.03, #학습률 설정\n",
    "        batch_size=256, #배치 사이즈 설정\n",
    "        epochs=200, #학습 횟수\n",
    "        impute_missing=True)\n",
    "\n",
    "        df_train, df_test = m.split_df(df=prcp_data, valid_p=0.2)\n",
    "        m.highlight_nth_step_ahead_of_each_forecast(step_number=m.n_forecasts)\n",
    "        metrics = m.fit(df_train, validation_df=df_test, freq=\"D\")\n",
    "        future = m.make_future_dataframe(prcp_data, periods=7, n_historic_predictions=len(prcp_data))\n",
    "        forecast = m.predict(future)\n",
    "        \n",
    "        forecast['yhat_avg'] = forecast[['yhat1', 'yhat2', 'yhat3', 'yhat4', 'yhat5', 'yhat6', 'yhat7']].mean(axis=1)\n",
    "        fore = forecast[['ds', 'y', 'yhat_avg']].tail(60)\n",
    "        fore.to_csv(f\"C:\\\\dohwi\\\\project\\\\forecast\\\\forecast_{indexnum}.csv\")\n",
    "        \n",
    "        exportrmsedata=True\n",
    "        rmse_eval('NeuralProphet', df_test, forecast)\n",
    "        \n",
    "        plot_predictions('NeuralProphet', df_test, forecast)\n",
    "        plt.savefig(f\"C:\\dohwi\\project\\predictions\\prediction_{indexnum}.png\")\n",
    "        plot_predictions60('NeuralProphet', df_test, forecast)\n",
    "        plt.savefig(f\"C:\\dohwi\\project\\machine_prediction\\prediction60_{indexnum}.png\")\n",
    "\n",
    "    except:\n",
    "    #indexnum이 있으나 오류가 나는 종목은 거래정지가 된 종목이다.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececc938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
